{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# AB Env and Parks does not give easy access to their real time stations.\n",
    "# They only provide the last few days of hourly data\n",
    "# urls for files look like this:\n",
    "# http://environment.alberta.ca/apps/Basins/data/text/snow/05CA805.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "#mpld3.enable_notebook()\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import xarray as xr\n",
    "from astropy.io import ascii\n",
    "import pytz\n",
    "# OS interaction\n",
    "import sys\n",
    "import os\n",
    "import glob\n",
    "import wget\n",
    "import seaborn as sns\n",
    "sns.set_context(\"talk\",font_scale=1.5)\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Paths to user files\n",
    "data_dir = os.path.normpath(r'F:\\Work\\e\\Data\\Obs\\Canada_Project_Sites\\CSAS_data') # Where to store data on local computer\n",
    "git_dir  = os.path.normpath(r'C:\\Users\\new356\\Google Drive\\Python\\CSAS') # This repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Stations we wish to download\n",
    "sta_code = ['05AD803','13A19S','05AA809','05DB802','05BJ805','05BL811','13A27S','05BL812','05CA805','05AA817','05BB803','05BF824']\n",
    "c_network = 'environmentAlberta'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data network\n",
    "network = 'AB_recent'\n",
    "\n",
    "# Location to download current AB station data\n",
    "download_dir = os.path.join(data_dir,network,'current')\n",
    "# Make if does not exist\n",
    "if not os.path.exists(download_dir):\n",
    "    os.makedirs(download_dir)\n",
    "    \n",
    "# Netcdf file to save to\n",
    "netcdf_dir   = os.path.join(data_dir,network,'netcdf')\n",
    "# Make if does not exist\n",
    "if not os.path.exists(netcdf_dir):\n",
    "    os.makedirs(netcdf_dir)\n",
    "netcdf_file_out =  os.path.join(netcdf_dir,'AB_NRT.nc')\n",
    "\n",
    "# Metadata for AB pillows \n",
    "meta_file         = 'AB_Station_Metadata.csv'\n",
    "meta_file_path    = os.path.join(git_dir,'metadata',meta_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download Near-real time AB data (Updated hourly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url_base = 'http://environment.alberta.ca/apps/Basins/data/text/snow/'\n",
    "file_ext = '.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "os.chdir(download_dir)\n",
    "Var_names = ['SWE','Snowdepth','AirTemperature','Precipitation']\n",
    "AB_2_BC_var_dict = {'Snow Water Equivalent':Var_names[0],'Snow Depth':Var_names[1],'Air Temperature':Var_names[2]}\n",
    "Var_units = ['mm','cm','C','mm']\n",
    "unit_dict = dict(zip(Var_names,Var_units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Remove previous files\n",
    "for cfile in sta_code:\n",
    "    try:\n",
    "        os.remove(cfile+file_ext)\n",
    "    except OSError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Download newest files\n",
    "for csta in sta_code:\n",
    "    try:\n",
    "        wget.download(url_base+csta+file_ext) \n",
    "    except OSError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import each data variable\n",
    "ds_list = []\n",
    "sta_list_used = []\n",
    "for (i,csta) in enumerate(sta_code):\n",
    "    cf = csta+file_ext\n",
    "    print(cf)\n",
    "    \n",
    "    # Load in to python\n",
    "    df = pd.read_csv(cf,index_col=1, skiprows=20, skipfooter=1, engine='python', parse_dates=True)\n",
    "    df.index.names = ['Time_MST']\n",
    "    \n",
    "    # Remove units\n",
    "    df = df[1:]\n",
    "    \n",
    "    # Rename columns\n",
    "    df = df.rename(columns = AB_2_BC_var_dict)\n",
    "    \n",
    "    # Drop Station No.\n",
    "    df = df.drop('Station No.', 1)\n",
    "    \n",
    "    # Force to numeric\n",
    "    df = df.convert_objects(convert_numeric=True)\n",
    "    \n",
    "    # df to ds\n",
    "    ds_c = xr.Dataset.from_dataframe(df)\n",
    "    # Add as coord\n",
    "    ds_c['staID'] = csta\n",
    "    ds_c.set_coords('staID',inplace=True)\n",
    "    \n",
    "    # Store as dict (if we have any data)\n",
    "    if ds_c.Time_MST.size>0:\n",
    "        ds_list.append(ds_c)\n",
    "        sta_list_used.append(csta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Merge into netcdf\n",
    "ds = xr.concat(ds_list,'staID')\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ds.staID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read in metadata provided by Stephen at AEP.DMNRT@gov.ab.ca\n",
    "metadata = pd.read_csv(meta_file_path, index_col='stnnumber', encoding = \"ISO-8859-1\", usecols=['stnname','stnnumber','stnlatitude','stnlongitude','stnelevationmet'])\n",
    "metadata.index.names = ['staID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extract only stations we are interested in\n",
    "metadata = metadata.loc[ds.staID.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## ADD UNITS\n",
    "# Add variable attributes (units), and fix variable names (remove spaces)\n",
    "for cvar in ds.data_vars:\n",
    "    # add units as attributes\n",
    "    ds.get(cvar).attrs['unit']   = unit_dict[cvar]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ## Add station metadata\n",
    "ds['station_name'] = xr.DataArray(metadata['stnname'],coords={'staID':metadata.index}, dims='staID')\n",
    "ds['Lat'] = xr.DataArray(metadata['stnlatitude'],coords={'staID':metadata.index}, dims='staID')\n",
    "ds['Lon'] = xr.DataArray(metadata['stnlongitude'],coords={'staID':metadata.index}, dims='staID')\n",
    "ds['Elevation'] = xr.DataArray(metadata['stnelevationmet'],coords={'staID':metadata.index}, dims='staID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ds.set_coords(['station_name','Lat','Lon','Elevation'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(ds.Time_MST,ds.SWE.T.values);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(ds.Time_MST,ds.Snowdepth.T.values);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(ds.Time_MST,ds.AirTemperature.T.values);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Adjust time zone to UTC\n",
    "# ISSUE here is that time zone is \"Current\" as in it changes between MDT and MST (dumb), so go with MST here as we most often care about snow during witner\n",
    "# MST to UTC (-7 hours)\n",
    "ds['Time_MST'] = ds.Time_MST + np.timedelta64(-7,'h')\n",
    "ds.rename({'Time_MST':'Time_UTC'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add Netowork\n",
    "ds.coords['network'] = xr.DataArray([c_network for x in ds.staID], dims='staID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save as netcdf file\n",
    "ds.to_netcdf(netcdf_file_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
