{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "#mpld3.enable_notebook()\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import xarray as xr\n",
    "from astropy.io import ascii\n",
    "import pytz\n",
    "# OS interaction\n",
    "import sys\n",
    "import os\n",
    "import glob\n",
    "import wget\n",
    "import seaborn as sns\n",
    "sns.set_context(\"talk\",font_scale=1.5)\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Paths to user files\n",
    "data_dir = os.path.normpath(r'F:\\Work\\e\\Data\\Obs\\Canada_Project_Sites\\CSAS_data') # Where to store data on local computer\n",
    "git_dir  = os.path.normpath(r'C:\\Users\\new356\\Google Drive\\Python\\CSAS') # This repo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data network\n",
    "network = 'BC_NRT'\n",
    "\n",
    "# Location to download current AB station data\n",
    "download_dir = os.path.join(data_dir,network,'current')\n",
    "# Make if does not exist\n",
    "if not os.path.exists(download_dir):\n",
    "    os.makedirs(download_dir)\n",
    "    \n",
    "# Netcdf file to save to\n",
    "netcdf_dir   = os.path.join(data_dir,network,'netcdf')\n",
    "# Make if does not exist\n",
    "if not os.path.exists(netcdf_dir):\n",
    "    os.makedirs(netcdf_dir)\n",
    "netcdf_file_out =  os.path.join(netcdf_dir,'BC_NRT.nc')\n",
    "\n",
    "# Metadata for AB pillows \n",
    "meta_file         = 'BC_Station_Metadata.csv'\n",
    "meta_file_path    = os.path.join(git_dir,'metadata',meta_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download Near-real time BC data (Updated hourly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "os.chdir(download_dir)\n",
    "BC_files = ['SW.csv','SD.csv','TA.csv','PC.csv']\n",
    "Var_names = ['SWE','Snowdepth','AirTemperature','Precipitation']\n",
    "Var_units = ['mm','cm','C','mm']\n",
    "c_network = 'bcRiverForecastCenter'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Remove previous files\n",
    "for cfile in BC_files:\n",
    "    try:\n",
    "        os.remove(cfile)\n",
    "    except OSError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100% [......................................................] 2249142 / 2249142"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['SW.csv', 'SD.csv', 'TA.csv', 'PC.csv']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download newest files\n",
    "url_base         = 'http://bcrfc.env.gov.bc.ca/data/asp/realtime/data/'\n",
    "[wget.download(url_base+cfile) for cfile in BC_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import metadata for each station\n",
    "metadata = pd.read_csv(meta_file_path,index_col=1,delimiter=',',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SW.csv\n",
      "SD.csv\n",
      "TA.csv\n",
      "PC.csv\n",
      "fixing Muskwa-Kechik error\n"
     ]
    }
   ],
   "source": [
    "# Import each data variable\n",
    "ds_dict   = {}\n",
    "unit_dict = {}\n",
    "for (i,cf) in enumerate(BC_files):\n",
    "    print(cf)\n",
    "    \n",
    "    # Load in to python\n",
    "    df = pd.read_csv(cf,index_col=0, skipfooter=1, engine='python', parse_dates=True)\n",
    "    var_name_full  = Var_names[i]\n",
    "    var_units = Var_units[i]\n",
    "    df.index.names = ['Time_UTC']\n",
    "    \n",
    "    # Check for error in PC.csv\n",
    "    if cf=='PC.csv':\n",
    "        print('fixing Muskwa-Kechik error')\n",
    "        df = df.rename(columns = {'4A34P Muskwa-Kechika':'4A34P Dowling Creek'})\n",
    "\n",
    "    # Store as dict\n",
    "    ds_dict[var_name_full] = df\n",
    "    unit_dict[var_name_full] = var_units\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Merge into netcdf\n",
    "ds = xr.Dataset(ds_dict)\n",
    "ds.rename({'dim_1':'staID'},inplace=True) # rename time\n",
    "ds['staID']        = [str(x).split(' ')[0] for x in ds.staID.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## ADD UNITS\n",
    "# Add variable attributes (units), and fix variable names (remove spaces)\n",
    "for cvar in ds.data_vars:\n",
    "    # add units as attributes\n",
    "    ds.get(cvar).attrs['unit']   = unit_dict[cvar]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Add station metadata\n",
    "ds['station_name'] = xr.DataArray(metadata['station'],coords={'staID':metadata.index}, dims='staID')\n",
    "ds['Lat'] = xr.DataArray(metadata['latitude'],coords={'staID':metadata.index}, dims='staID')\n",
    "ds['Lon'] = xr.DataArray(metadata['longitude'],coords={'staID':metadata.index}, dims='staID')\n",
    "ds['Elevation'] = xr.DataArray(metadata['elevation'],coords={'staID':metadata.index}, dims='staID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:         (Time_UTC: 7672, staID: 72)\n",
       "Coordinates:\n",
       "  * staID           (staID) object '1A01P' '1A02P' '1A03P' '1A05P' '1A12P' ...\n",
       "  * Time_UTC        (Time_UTC) datetime64[ns] 2016-10-01 2016-10-01T01:00:00 ...\n",
       "    station_name    (staID) object 'Yellowhead Lake' 'McBride' 'Barkerville' ...\n",
       "    Lat             (staID) float64 52.91 53.31 53.06 53.95 56.02 54.11 54.3 ...\n",
       "    Lon             (staID) float64 -118.5 -120.3 -121.5 -121.4 -126.3 ...\n",
       "    Elevation       (staID) float64 1.852e+03 1.58e+03 1.48e+03 1.693e+03 ...\n",
       "Data variables:\n",
       "    AirTemperature  (Time_UTC, staID) float64 5.3 7.5 8.8 6.4 2.5 7.7 1.1 ...\n",
       "    Precipitation   (Time_UTC, staID) float64 787.0 663.0 420.0 nan nan ...\n",
       "    SWE             (Time_UTC, staID) float64 2.0 0.0 1.0 0.0 0.0 10.0 22.0 ...\n",
       "    Snowdepth       (Time_UTC, staID) float64 nan nan 1.0 0.0 0.0 66.0 10.0 ..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Move to coords\n",
    "ds.set_coords(['station_name','Lat','Lon','Elevation'],inplace=True)\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:         (Time_UTC: 7672, staID: 72)\n",
       "Coordinates:\n",
       "  * staID           (staID) object '1A01P' '1A02P' '1A03P' '1A05P' '1A12P' ...\n",
       "  * Time_UTC        (Time_UTC) datetime64[ns] 2016-10-01 2016-10-01T01:00:00 ...\n",
       "    station_name    (staID) object 'Yellowhead Lake' 'McBride' 'Barkerville' ...\n",
       "    Lat             (staID) float64 52.91 53.31 53.06 53.95 56.02 54.11 54.3 ...\n",
       "    Lon             (staID) float64 -118.5 -120.3 -121.5 -121.4 -126.3 ...\n",
       "    Elevation       (staID) float64 1.852e+03 1.58e+03 1.48e+03 1.693e+03 ...\n",
       "Data variables:\n",
       "    AirTemperature  (staID, Time_UTC) float64 5.3 5.1 3.9 3.7 3.6 3.3 3.0 ...\n",
       "    Precipitation   (staID, Time_UTC) float64 787.0 787.0 787.0 787.0 787.0 ...\n",
       "    SWE             (staID, Time_UTC) float64 2.0 2.0 2.0 2.0 2.0 2.0 2.0 ...\n",
       "    Snowdepth       (staID, Time_UTC) float64 nan nan nan nan nan nan nan ..."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = ds.T\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  2.,   2.,   2., ...,  nan,  nan,  nan],\n",
       "       [  0.,   0.,   0., ...,   9.,   9.,   9.],\n",
       "       [  1.,   1.,   1., ...,   0.,   0.,   0.],\n",
       "       ..., \n",
       "       [  2.,   2.,   2., ...,   0.,   0.,   0.],\n",
       "       [ nan,  nan,  nan, ...,   5.,   5.,   4.],\n",
       "       [  0.,   0.,   0., ...,   0.,   0.,   0.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.SWE.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add Network\n",
    "ds.coords['network'] = xr.DataArray([c_network for x in ds.staID], dims='staID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Save as netcdf file\n",
    "ds.to_netcdf(netcdf_file_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
