{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import xarray as xr\n",
    "from astropy.io import ascii\n",
    "import pytz\n",
    "# OS interaction\n",
    "import sys\n",
    "import os\n",
    "import glob\n",
    "import seaborn as sns\n",
    "sns.set_context(\"talk\",font_scale=1.5)\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Paths to user files\n",
    "data_dir = os.path.normpath(r'F:\\Work\\e\\Data\\Obs\\Canada_Project_Sites\\CSAS_data') # Where to store data on local computer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hourly_merged = os.path.join(data_dir,'merged','Hourly_Merged.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "QC_dir = os.path.join(data_dir,'QC')\n",
    "# Make if does not exist\n",
    "if not os.path.exists(QC_dir):\n",
    "    os.makedirs(QC_dir)\n",
    "netcdf_file_out = os.path.join(QC_dir, 'Hourly_QC.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QC merged data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ds_merged = xr.open_dataset(hourly_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ds_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(ds_merged.Time_UTC,ds_merged.SnowWaterEquivelentA.values);\n",
    "plt.figure()\n",
    "plt.plot(ds_merged.Time_UTC,ds_merged.SnowDepthA.values);\n",
    "plt.figure()\n",
    "plt.plot(ds_merged.Time_UTC,ds_merged.AirtemperatureA.values);\n",
    "plt.figure()\n",
    "plt.plot(ds_merged.Time_UTC,ds_merged.CummulativePrecipitationA.values);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ds = ds_merged.copy() # Make copy to QC (allows comparison at end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quality control data here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Quality Control\n",
    "\n",
    "## Max and min\n",
    "# SnowWaterEquivelentA\n",
    "max_swe = 3 # m\n",
    "min_swe = 0 # m\n",
    "ds['SnowWaterEquivelentA'] = ds.SnowWaterEquivelentA.where((ds.SnowWaterEquivelentA<max_swe) &  (ds.SnowWaterEquivelentA>min_swe))\n",
    "\n",
    "# SD\n",
    "max_sd = 5.50 # m\n",
    "min_sd = 0 # m\n",
    "ds['SnowDepthA'] = ds.SnowDepthA.where((ds.SnowDepthA<max_sd) &                                                              \n",
    "                                               (ds.SnowDepthA>min_sd))\n",
    "\n",
    "# Precip\n",
    "max_p = 3 # m\n",
    "min_p = 0 # m\n",
    "ds['CummulativePrecipitationAA'] = ds.CummulativePrecipitationA.where((ds.CummulativePrecipitationA<max_p) &                                                              \n",
    "                                               (ds.CummulativePrecipitationA>min_p))\n",
    "\n",
    "# Tair\n",
    "max_tar = 40 # C\n",
    "min_tar = -50 # C\n",
    "ds['AirtemperatureA'] = ds.AirtemperatureA.where((ds.AirtemperatureA<max_tar) & \n",
    "                                                        (ds.AirtemperatureA>min_tar))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_outliers_via_filter(x,threshold,window):\n",
    "    if(sum(np.isnan(x.values))/len(x.values)>0.9): # Mostly nan, just return x, otherwise filter fails\n",
    "        return x\n",
    "    else: # Have some data, apply the median filter and remove differences greater than threshold\n",
    "        # Apply median filter\n",
    "        temp = x.to_series().rolling(window=window, center=True).median().fillna(method='bfill').fillna(method='ffill')\n",
    "        # Take difference between filter and orig data\n",
    "        difference = np.abs(x.to_series() - temp)\n",
    "        # Find those data values that the diff was less than the user supplied threshold\n",
    "        inlier_idx  = difference < threshold\n",
    "        return x.where(inlier_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## ROC - Use median filter to find values\n",
    "\n",
    "# SD\n",
    "SD_ROC_threshold = 50/100 # m/hr\n",
    "SD_ROC_window = 10 # dt (hrs)\n",
    "ds['SnowDepthA'] = ds.SnowDepthA.groupby('staID').apply(lambda x: remove_outliers_via_filter(x,SD_ROC_threshold,SD_ROC_window))\n",
    "\n",
    "# SnowWaterEquivelentA\n",
    "SnowWaterEquivelentA_ROC_threshold = 5/1000 # m/hr\n",
    "SnowWaterEquivelentA_ROC_window = 10 # dt (hrs)\n",
    "ds['SnowWaterEquivelentA'] = ds.SnowWaterEquivelentA.groupby('staID').apply(lambda x: remove_outliers_via_filter(x,SnowWaterEquivelentA_ROC_threshold,SnowWaterEquivelentA_ROC_window))\n",
    "\n",
    "# Accumulated Precip (total)\n",
    "P_ROC_threshold = 20/1000 # m/hr\n",
    "P_ROC_window = 48 # dt (hrs)\n",
    "ds['CummulativePrecipitationA'] = ds.CummulativePrecipitationA.groupby('staID').apply(lambda x: remove_outliers_via_filter(x,P_ROC_threshold,P_ROC_window))\n",
    "\n",
    "# Air temperature\n",
    "T_ROC_threshold = 10 # C/hr\n",
    "T_ROC_window = 6 # dt (hrs)\n",
    "ds['AirtemperatureA'] = ds.AirtemperatureA.groupby('staID').apply(lambda x: remove_outliers_via_filter(x,T_ROC_threshold,T_ROC_window))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import mpld3\n",
    "# mpld3.enable_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(ds.Time_UTC,ds.SnowWaterEquivelentA.values);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(ds.Time_UTC,ds.SnowDepthA.values);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(ds.Time_UTC,ds.AirtemperatureA.values);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(ds.Time_UTC,ds.CummulativePrecipitationA.values);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Save as netcdf file\n",
    "ds.to_netcdf(netcdf_file_out)\n",
    "print(netcdf_file_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
